{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7186178d-d3db-4da7-afb2-197e7ce26ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.layers import GRU \n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "def adj_r2_score(r2, n, k):\n",
    "    return 1-((1-r2)*((n-1)/(n-k-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03e830f-5aba-4351-ac4f-20bbbb88b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de24ebe6-0861-459f-afcf-3dbf660f19d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 6, 50)             10400     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 6, 64)             22272     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 2, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,153\n",
      "Trainable params: 45,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8599667-c5e6-4acc-8388-81862f8f0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbp_jpy_data = pd.read_csv('GBPJPY_H4.csv')\n",
    "gold_data = pd.read_csv('GOLD_H4.csv')\n",
    "us500_data = pd.read_csv('US500_H4.csv')\n",
    "gbp_nzd_data = pd.read_csv('GBPNZD_H4.csv')\n",
    "gbp_aud_data = pd.read_csv('GBPAUD_H4.csv')\n",
    "\n",
    "list_of_df = []\n",
    "\n",
    "list_of_df.append(gbp_jpy_data)\n",
    "list_of_df.append(gold_data)\n",
    "list_of_df.append(us500_data)\n",
    "list_of_df.append(gbp_nzd_data)\n",
    "list_of_df.append(gbp_aud_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61258dd0-75d9-49d4-a41a-b2a129f68f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_of_df = []\n",
    "for x in list_of_df:\n",
    "    x[\"time\"] = pd.to_datetime(x[\"time\"])\n",
    "    ind_exchange_data = x.set_index([\"time\"], drop=True)\n",
    "    index_list_of_df.append(ind_exchange_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98049dbe-f2e3-4bc7-bd4d-d67a7e2805b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17832\n",
      "8794\n",
      "4990\n",
      "17832\n",
      "17832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qs/tq01j0l577ddz8gg_tnvhl6m0000gn/T/ipykernel_11703/1250389640.py:8: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  clipped_data = x.loc[start_date:cut_off_date]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "#Take a start date and end date\n",
    "start_date = pd.Timestamp('31-12-10')\n",
    "cut_off_date = pd.Timestamp('22-06-22')\n",
    "\n",
    "clipped_data_list = []\n",
    "\n",
    "for x in index_list_of_df:\n",
    "    clipped_data = x.loc[start_date:cut_off_date]\n",
    "    print(len(clipped_data))\n",
    "    clipped_data_list.append(clipped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c72091d-1751-4902-9a91-28312a953259",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1ebdda2-e6b7-4bab-b79c-369562b33e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0070 - rmse: 0.0839\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0086 - rmse: 0.0925\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0120 - rmse: 0.1097\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0144 - rmse: 0.1200\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0128 - rmse: 0.1130\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0139 - rmse: 0.1180\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0124 - rmse: 0.1112\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0135 - rmse: 0.1160\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0205 - rmse: 0.1432\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0163 - rmse: 0.1277\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0167 - rmse: 0.1294\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0187 - rmse: 0.1368\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0181 - rmse: 0.1346\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0293 - rmse: 0.1711\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0296 - rmse: 0.1721\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1420 - rmse: 0.3768\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.2710 - rmse: 0.5206\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0191 - rmse: 0.1382\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0514 - rmse: 0.2267\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0346 - rmse: 0.1859\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0185 - rmse: 0.1361\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0133 - rmse: 0.1154\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0120 - rmse: 0.1097\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0111 - rmse: 0.1054\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0115 - rmse: 0.1072\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0119 - rmse: 0.1089\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0106 - rmse: 0.1027\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0106 - rmse: 0.1027\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0106 - rmse: 0.1029\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0102 - rmse: 0.1010\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0096 - rmse: 0.0979\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0112 - rmse: 0.1058\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0119 - rmse: 0.1091\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0108 - rmse: 0.1039\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0101 - rmse: 0.1003\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0132 - rmse: 0.1149\n",
      "Epoch 18: early stopping\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0083 - rmse: 0.0913\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0078 - rmse: 0.0883\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0085 - rmse: 0.0921\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0078 - rmse: 0.0881\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0071 - rmse: 0.0841\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0069 - rmse: 0.0830\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0066 - rmse: 0.0812\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0067 - rmse: 0.0819\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0067 - rmse: 0.0819\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0068 - rmse: 0.0825\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0081 - rmse: 0.0899\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.0077 - rmse: 0.0878\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "for x in clipped_data_list: \n",
    "    df = x[[\"close\"]]\n",
    "    adjusted_data_frame = np.array(x)\n",
    "    entries = int(len(x))\n",
    "    split_length = int(entries * 0.8)\n",
    "    split_date = x.index[split_length]\n",
    "    \n",
    "    train = df.loc[:split_date]\n",
    "    test = df.loc[split_date:]\n",
    "    \n",
    "    train_sc = sc.fit_transform(train)\n",
    "    test_sc = sc.transform(test)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    timesteps = 6\n",
    "    for i in range(timesteps, train.shape[0]):\n",
    "        X.append(train_sc[i-timesteps:i, 0])\n",
    "        y.append(train_sc[i, 0])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "    history_model_lstm = new_model.fit(X, y, epochs=100, batch_size=192, verbose=1, shuffle=False, callbacks=[early_stop])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c964ae31-7391-44f8-87a2-72ba13401ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_numbers(lst):\n",
    "    classifications = []\n",
    "    prev_num = lst[0]\n",
    "    for i, num in enumerate(lst[1:], start=1):\n",
    "        if num > prev_num:\n",
    "            classifications.append('green')\n",
    "        else:\n",
    "            classifications.append('red')\n",
    "        prev_num = num\n",
    "    return classifications\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be86932-0a1f-4651-b518-982fa824f2f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clipped_data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Generate all the test data that is needed to make the predictions and display the predictions \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m count, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mclipped_data_list\u001b[49m): \n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m x[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      5\u001b[0m     adjusted_data_frame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clipped_data_list' is not defined"
     ]
    }
   ],
   "source": [
    "#Generate all the test data that is needed to make the predictions and display the predictions \n",
    "\n",
    "for count, x in enumerate(clipped_data_list): \n",
    "    df = x[[\"close\"]]\n",
    "    adjusted_data_frame = np.array(x)\n",
    "    entries = int(len(x))\n",
    "    split_length = int(entries * 0.8)\n",
    "    split_date = x.index[split_length]\n",
    "    \n",
    "   \n",
    "    test = df.loc[split_date:]\n",
    "    test_sc = sc.transform(test)\n",
    "    \n",
    "    y_test = test_sc[1:]\n",
    "    \n",
    "    timesteps = 6\n",
    "    X_test_lstm = []\n",
    "    Y_test_lstm = []\n",
    "    \n",
    "    for i in range(timesteps, test.shape[0]):\n",
    "        X_test_lstm.append(test_sc[i-timesteps:i, 0])\n",
    "        Y_test_lstm.append(test_sc[i, 0])\n",
    "    \n",
    "    X_test_lstm = np.array(X_test_lstm)\n",
    "    Y_test_lstm = np.array(Y_test_lstm)\n",
    "    X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], X_test_lstm.shape[1], 1))\n",
    "    \n",
    "    y_pred_test_lstm = new_model.predict(X_test_lstm)\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(y_test, label='True')\n",
    "    plt.plot(y_pred_test_lstm, label='LSTM')\n",
    "    plt.title(\"LSTM's_Prediction\")\n",
    "    plt.xlabel('Observation')\n",
    "    plt.ylabel('INR_Scaled')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    last_prediction = y_pred_test_lstm[-timesteps:]\n",
    "    last_prediction = np.array(last_prediction)\n",
    "\n",
    "    for i in range(10):\n",
    "        next_input = np.array([last_prediction[-timesteps:]])\n",
    "        next_input = next_input.reshape((next_input.shape[0], next_input.shape[1], 1))\n",
    "        next_prediction = new_model.predict(next_input, verbose=0)\n",
    "        last_prediction = np.append(last_prediction, next_prediction[0])\n",
    "    \n",
    "\n",
    "    lstm_future = np.array(last_prediction[-10:]).reshape(-1,1)\n",
    "    inverse_transformed_data_lstm = sc.inverse_transform(lstm_future).flatten().tolist()   \n",
    "    lstm_rounded_numbers = [round(x, 5) for x in inverse_transformed_data_lstm]\n",
    "    \n",
    "    future_lstm_prices = []\n",
    "    last_lstm = sc.inverse_transform(y_pred_test_lstm[-1:])\n",
    "    future_lstm_prices.append(round(float(last_lstm[0]),5))\n",
    "    for z in lstm_rounded_numbers:\n",
    "        future_lstm_prices.append(z) \n",
    "    \n",
    "    clipped_len = len(x)\n",
    "    future_comparison = index_list_of_df[count].iloc[clipped_len-1:]\n",
    "    future = future_comparison.iloc[0:11]\n",
    "    future_prices_table = future[\"close\"]\n",
    "    \n",
    "    \n",
    "    future_prices = []\n",
    "    for z in future_prices_table:\n",
    "        future_prices.append(z)\n",
    "    \n",
    "    print(future_prices)\n",
    "        \n",
    "    classifications1 = classify_numbers(future_lstm_prices)\n",
    "    classifications2 = classify_numbers(future_prices)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "    ax1.plot(future_lstm_prices, color='blue')\n",
    "    for i, c in enumerate(classifications1):\n",
    "        if c == 'green':\n",
    "            ax1.axvspan(i, i+1, facecolor='green', alpha=0.2)\n",
    "        elif c == 'red':\n",
    "            ax1.axvspan(i, i+1, facecolor='red', alpha=0.2)\n",
    "\n",
    "    ax2.plot(future_prices, color='blue')\n",
    "    for i, c in enumerate(classifications2):\n",
    "        if c == 'green':\n",
    "            ax2.axvspan(i, i+1, facecolor='green', alpha=0.2)\n",
    "        elif c == 'red':\n",
    "            ax2.axvspan(i, i+1, facecolor='red', alpha=0.2)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6608282-9551-4061-915d-48523c399e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958760e-269b-40bf-9dad-f130e6007869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
